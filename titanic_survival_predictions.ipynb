{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eirSTPbOBXLr"
      },
      "source": [
        "# HW 2\n",
        "## Titanic Survival Predictions\n",
        "In this dataset, you will train a logistic regression model that can predict the survivors based on a set of features about the passenger. Start first by taking some time to understand your data. You can find more info about the data and its breakdown in this link https://www.kaggle.com/c/titanic/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3wg1I7vBXLt"
      },
      "source": [
        "### Start with Data Exploring\n",
        "Your data is split into two files. One for training and one for testing. Load both and find out the number of samples and features in each file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LDMpRLPJBXLu",
        "outputId": "c6ede084-d2bb-4c81-82be-65511acdf8c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c0e1420989b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylab\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pylab as plt\n",
        "\n",
        "df = pd.read_csv('train.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wanJr_yHBXLw"
      },
      "outputs": [],
      "source": [
        "\n",
        "df1 = pd.read_csv('test.csv')\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbpJGqQuBXLw"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()\n",
        "print(\"Train Shape:\",df.shape)\n",
        "df1.isnull().sum()\n",
        "print(\"Test Shape:\",df1.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtVlLpk7BXLx"
      },
      "source": [
        "How many survivors in the training set?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XS9KnJqPBXLx"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkwtod-uBXLx"
      },
      "source": [
        "Can you find Jack and Rose in the data? Use some code. You probably won't find them as they were fictional characters. See if you can find Beatrice Irene Sandstorm? Read here about her https://www.encyclopedia-titanica.org/titanic-survivor/beatrice-irene-sandstrom.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFfKfdaXBXLy"
      },
      "outputs": [],
      "source": [
        "boolean_findings = df['Name'].str.contains('Beatrice Irene Sandstorm')\n",
        "boolean_findings\n",
        "\n",
        "total_occurence = boolean_findings.sum()\n",
        "\n",
        "if(total_occurence > 0):\n",
        "    print(\"yes the string is present in the column\")\n",
        "else:\n",
        "    print(\"The Name is not in the data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ATmQaS6BXLy"
      },
      "source": [
        "### Does features make a difference?\n",
        "In the training dataset (file)\n",
        "- Pclass - Usually, higher class (class 1) meant a more expensive fare and the other classes paid lesser to be on the ship. What was the survival rate per class?\n",
        "- Sex — What was the survival rate of women?\n",
        "- SibSp — What was the survival rate based on number of siblings the passenger had on the ship?\n",
        "- Parch — What was the survival rate based on number of parents/children the passenger had on the ship?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_f3nLyVsBXLz"
      },
      "outputs": [],
      "source": [
        "plt.rc('figure', figsize=(10, 5))\n",
        "\n",
        "# Size of matplotlib figures that contain subplots\n",
        "fizsize_with_subplots = (10, 10)\n",
        "\n",
        "# Size of matplotlib histogram bins\n",
        "bin_size = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pU2pBLtoBXLz"
      },
      "outputs": [],
      "source": [
        "def bar_chart(feature):\n",
        "    survived = df[df['Survived']==1][feature].value_counts()\n",
        "    dead = df[df['Survived']==0][feature].value_counts()\n",
        "    data = pd.DataFrame([survived,dead])\n",
        "    data.index = ['Survived','Dead']\n",
        "    data.plot(kind='bar',stacked=True, figsize=(10,5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rsZ3UZBBXL0"
      },
      "source": [
        "## Pclass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fd8MMrk2BXL0"
      },
      "outputs": [],
      "source": [
        "bar_chart('Pclass')\n",
        "print(\"Survived :\\n\",df[df['Survived']==1]['Pclass'].value_counts())\n",
        "print(\"Dead:\\n\",df[df['Survived']==0]['Pclass'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7VNPpebBXL1"
      },
      "source": [
        "# sex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9Du6aELBXL1"
      },
      "outputs": [],
      "source": [
        "bar_chart('Sex')\n",
        "print(\"Survived :\\n\",df[df['Survived']==1]['Sex'].value_counts())\n",
        "print(\"Dead:\\n\",df[df['Survived']==0]['Sex'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj-Aa8VbBXL2"
      },
      "source": [
        "# sibSp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTo6zPlyBXL2"
      },
      "outputs": [],
      "source": [
        "bar_chart('SibSp')\n",
        "print(\"Survived :\\n\",df[df['Survived']==1]['SibSp'].value_counts())\n",
        "print(\"Dead:\\n\",df[df['Survived']==0]['SibSp'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9LYPRvABXL3"
      },
      "source": [
        "The Chart confirms a person aboarded with more than 2 siblings or spouse more likely survived.\n",
        "The Chart confirms a person aboarded without siblings or spouse more likely dead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0L6MhcIMBXL3"
      },
      "outputs": [],
      "source": [
        "bar_chart('Parch')\n",
        "print(\"Survived :\\n\",df[df['Survived']==1]['Parch'].value_counts())\n",
        "print(\"Dead:\\n\",df[df['Survived']==0]['Parch'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk3xmIG2BXL4"
      },
      "source": [
        "The Chart confirms a person aboarded with more than 2 parents or children more likely survived.\n",
        "The Chart confirms a person aboarded alone more likely dead"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeFJBJ7zBXL4"
      },
      "source": [
        "Plot two histogram based on the age. One for the survivors and other for non survivors. According to the histogram was Jack more likely to survive or not survive and why?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvhH-wlyBXL5"
      },
      "outputs": [],
      "source": [
        "df['AgeFill'] = df['Age']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPcUKlBzBXL5"
      },
      "outputs": [],
      "source": [
        "df['AgeFill'] = df['AgeFill'] \\\n",
        "                        .groupby([df['Sex'], df['Pclass']]) \\\n",
        "                        .apply(lambda x: x.fillna(x.median()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8l1iE_PaBXL6"
      },
      "outputs": [],
      "source": [
        "len(df[df['AgeFill'].isnull()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnCNQLBxBXL6"
      },
      "outputs": [],
      "source": [
        "max_age = max(df['AgeFill'])\n",
        "max_age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Alm6jJv9BXL7"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 1, figsize=fizsize_with_subplots)\n",
        "n_equal_bins = 1\n",
        "# Histogram of AgeFill segmented by Survived\n",
        "data1 = df[df['Survived'] == 0]['Age']\n",
        "data2 = df[df['Survived'] == 1]['Age']\n",
        "max_age = max(df['AgeFill'])\n",
        "axes[0].hist([data1, data2],\n",
        "             bins= 8,  #bin = max_age / bin_size\n",
        "             range=(1, max_age),\n",
        "             stacked=True)\n",
        "axes[0].legend(('Died', 'Survived'), loc='best')\n",
        "axes[0].set_title('Survivors by Age Groups Histogram')\n",
        "axes[0].set_xlabel('Age')\n",
        "axes[0].set_ylabel('Count')\n",
        "\n",
        "# Scatter plot Survived and AgeFill\n",
        "axes[1].scatter(df['Survived'], df['AgeFill'])\n",
        "axes[1].set_title('Survivors by Age Plot')\n",
        "axes[1].set_xlabel('Survived')\n",
        "axes[1].set_ylabel('Age')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vzlgu_cZBXL7"
      },
      "source": [
        "Unfortunately, the graphs above do not seem to clearly show any insights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98h_Ytx5BXL7"
      },
      "source": [
        "Divide the age histograms into 3 X 2 subplots. Left column is for non survival data and the right one is for survivors. Each row is for one of the three PClasses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDUf87aXBXL8",
        "outputId": "820a4709-36f5-408a-9129-0b219075932c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ea8415b8a3ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABmS2HOiBXL8"
      },
      "outputs": [],
      "source": [
        "# Set up a grid of plots\n",
        "fig = plt.figure(figsize=fizsize_with_subplots)\n",
        "fig_dims = (3, 2)\n",
        "\n",
        "# Plot death and survival counts\n",
        "plt.subplot2grid(fig_dims, (0, 0))\n",
        "df['Survived'].value_counts().plot(kind='bar',\n",
        "                                         title='Death and Survival Counts')\n",
        "\n",
        "# Plot Pclass counts\n",
        "plt.subplot2grid(fig_dims, (0, 1))\n",
        "df['Pclass'].value_counts().plot(kind='bar',\n",
        "                                       title='Passenger Class Counts')\n",
        "\n",
        "# Plot Sex counts\n",
        "plt.subplot2grid(fig_dims, (1, 0))\n",
        "df['Sex'].value_counts().plot(kind='bar',\n",
        "                                    title='Gender Counts')\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "# Plot Embarked counts\n",
        "plt.subplot2grid(fig_dims, (1, 1))\n",
        "df['Embarked'].value_counts().plot(kind='bar',\n",
        "                                         title='embark Counts')\n",
        "\n",
        "# Plot the Age histogram\n",
        "plt.subplot2grid(fig_dims, (2, 0))\n",
        "df['Age'].hist()\n",
        "plt.title('Age Histogram')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-YkxDujBXL8"
      },
      "source": [
        "## Fix missing Data in the Training Dataset\n",
        "Which features in the training contains missing values? and how many missing values are there?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2q5S4d7BXL9"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFByxVHyBXL9"
      },
      "outputs": [],
      "source": [
        "df[df['Embarked'].isnull()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcFBbsG1BXL9"
      },
      "outputs": [],
      "source": [
        "df[df['Age'].isnull()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTIlj5EuBXL9"
      },
      "outputs": [],
      "source": [
        "df[df['Cabin'].isnull()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIXvEFb1BXL9"
      },
      "outputs": [],
      "source": [
        " print(\" \\nCount total NaN in a DataFrame : \\n\\n\",\n",
        "       df.isnull().sum().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4CshELVBXL9"
      },
      "source": [
        "Find out the median age grouped by PClass and gender. Clean up the data by substituting the nans by the median from the corresponding PClass and gender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYwUvQKQBXL-"
      },
      "outputs": [],
      "source": [
        "df.groupby([\"Sex\",'Pclass']).median()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfsnIolaBXL-"
      },
      "source": [
        "The median age grouped by PClass and gender is 31.0 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Seqs-UV6BXL-"
      },
      "outputs": [],
      "source": [
        "df[['Sex','Pclass']]=df[['Sex','Pclass']].fillna(df.median().iloc[0])\n",
        "df[['Sex','Pclass']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kMtbnlHBXL-"
      },
      "source": [
        "For the Embarked column, substitute the missing value with the highest occurence value among the entire dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3okaO_fDBXL-"
      },
      "outputs": [],
      "source": [
        "df['Embarked']=df['Embarked'].fillna(df.mode().iloc[0])\n",
        "df['Embarked']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBVQz7ZtBXL-"
      },
      "source": [
        "## Let's build our Model\n",
        "Cabin, Name, ticket and Passenger Id are not important to our ML model. Let's get rid of them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Qch1bgpBXL-"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULeO12FCBXL_"
      },
      "outputs": [],
      "source": [
        "df= df.drop(labels=['Name', 'PassengerId', 'Ticket', 'Cabin'], axis= 1)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6khJXdqeBXL_"
      },
      "source": [
        "Make sure now that your data does not have any nulls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDBTzAZdBXL_"
      },
      "outputs": [],
      "source": [
        "df.dtypes[df.dtypes.map(lambda x: x == 'object')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKKo_RBSBXL_"
      },
      "outputs": [],
      "source": [
        "df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCog3UIfBXL_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j20IMDr6BXL_"
      },
      "outputs": [],
      "source": [
        "print(\" \\nCount total NaN in a DataFrame : \\n\\n\",\n",
        "      df.isnull().sum().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riGsUcGWBXMA"
      },
      "source": [
        "We need to convert some of our features to categories and numbers instead of letters as logistic regression model won't be able to decode them. Map the embarked variable into 0,1, and 2 and the sex variable into 0 and 1\n",
        "\n",
        "% hint: `df_train['Embarked'].astype('category').cat.codes`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sH0cLeWaBXMA"
      },
      "outputs": [],
      "source": [
        "df['Embarked'].astype('category').cat.codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRd7CzK1BXMA"
      },
      "outputs": [],
      "source": [
        "df['Sex'].astype('category').cat.codes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycns88ueBXMA"
      },
      "source": [
        "You are now ready to build a logistic regression model and fit it. You do not to split your data since I have already splitted for you in 2 different files so use all the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jl7hQAHoBXMA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lgMM78wBXMA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VK1a2_7rBXMA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCXilL8rBXMA"
      },
      "source": [
        "Show the training score. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YiK_pyQBXMB"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TliCFnEABXMB"
      },
      "source": [
        "What are the coefficients. Make a plot that shows the importance of each feature in your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRel1nyTBXMB"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eggR1moBXMB"
      },
      "source": [
        "Use the logistic regression model on the test data to predict who will survive. You may need to do same cleaning you have done in the training data to the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPhTpyuCBXMB"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB43KqwhBXMB"
      },
      "source": [
        "How many will survive from the test dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzQQwgzeBXMB"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8XnhPo3BXMB"
      },
      "source": [
        "# Chapter 3 exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikAswqsTBXMC"
      },
      "source": [
        "**A.** Try to build a classifier for the MNIST dataset that achieves over 97% accuracy on the test set. Hint: the `KNeighborsClassifier` works quite well for this task; you just need to find good hyperparameter values (try a grid search on the `weights` and `n_neighbors` hyperparameters)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y36sv_ynBXMC"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kep9_IzNBXMC"
      },
      "outputs": [],
      "source": [
        "X, y = mnist[\"data\"], mnist[\"target\"]\n",
        "X.shape\n",
        "print ((70000, 784))\n",
        "y.shape\n",
        "print((70000,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znVMmsAIBXMC"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "some_digit = X[36000]\n",
        "some_digit_image = some_digit.reshape(28, 28)\n",
        "plt.imshow(some_digit_image, cmap = matplotlib.cm.binary,\n",
        "interpolation=\"nearest\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4T6yCyKBXMC"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0Ur0dt0BXMC"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "param_grid = [{'weights': [\"uniform\", \"distance\"], 'n_neighbors': [3, 4, 5]}]\n",
        "\n",
        "knn_clf = KNeighborsClassifier()\n",
        "grid_search = GridSearchCV(knn_clf, param_grid, cv=5, verbose=3, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcNVztN5BXMD"
      },
      "outputs": [],
      "source": [
        "grid_search.best_params_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHS922u7BXMD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = grid_search.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kqH2Ig3BXMD"
      },
      "source": [
        "**B.** Write a function that can shift an MNIST image in any direction (left, right, up, or down) by one pixel. You can use the shift() function from the scipy.ndimage.interpolation module. For example, shift(image, [2, 1], cval=0) shifts the image two pixels down and one pixel to the right. Then, for each image in the training set, create four shifted copies (one per direction) and add them to the training set. Finally, train your best model on this expanded training set and measure its accuracy on the test set. You should observe that your model performs even better now! This technique of artificially growing the training set is called data augmentation or training set expansion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8R-te33BXMD"
      },
      "outputs": [],
      "source": [
        "from scipy.ndimage.interpolation import shift\n",
        "\n",
        "def shift_image(image, dx, dy):\n",
        "    image = image.reshape((28, 28))\n",
        "    shifted_image = shift(image, [dy, dx], cval=0, mode=\"constant\")\n",
        "    return shifted_image.reshape([-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDch4x28BXMD"
      },
      "outputs": [],
      "source": [
        "image = X_train[1000]\n",
        "shifted_image_down = shift_image(image, 0, 5)\n",
        "shifted_image_left = shift_image(image, -5, 0)\n",
        "\n",
        "plt.figure(figsize=(12,3))\n",
        "plt.subplot(131)\n",
        "plt.title(\"Original\", fontsize=14)\n",
        "plt.imshow(image.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
        "plt.subplot(132)\n",
        "plt.title(\"Shifted down\", fontsize=14)\n",
        "plt.imshow(shifted_image_down.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
        "plt.subplot(133)\n",
        "plt.title(\"Shifted left\", fontsize=14)\n",
        "plt.imshow(shifted_image_left.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8pLYzmeBXMD"
      },
      "outputs": [],
      "source": [
        "X_train_augmented = [image for image in X_train]\n",
        "y_train_augmented = [label for label in y_train]\n",
        "\n",
        "for dx, dy in ((1, 0), (-1, 0), (0, 1), (0, -1)):\n",
        "    for image, label in zip(X_train, y_train):\n",
        "        X_train_augmented.append(shift_image(image, dx, dy))\n",
        "        y_train_augmented.append(label)\n",
        "\n",
        "X_train_augmented = np.array(X_train_augmented)\n",
        "y_train_augmented = np.array(y_train_augmented)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhTGFREzBXMD"
      },
      "outputs": [],
      "source": [
        "shuffle_idx = np.random.permutation(len(X_train_augmented))\n",
        "X_train_augmented = X_train_augmented[shuffle_idx]\n",
        "y_train_augmented = y_train_augmented[shuffle_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6OT57nPBXME"
      },
      "outputs": [],
      "source": [
        "knn_clf = KNeighborsClassifier(**grid_search.best_params_)\n",
        "knn_clf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPakw4QNBXME"
      },
      "outputs": [],
      "source": [
        "knn_clf.fit(X_train_augmented, y_train_augmented)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBkwHS0FBXME"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_pred = knn_clf.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "titanic survival predictions",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}